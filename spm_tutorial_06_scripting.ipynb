{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5fa325e",
   "metadata": {},
   "source": [
    "# SPM Tutorial #6: Scripting\n",
    "\n",
    "## Sections\n",
    "- Creating the Template\n",
    "- File Selection and File Splitting\n",
    "- Filling in the Preprocessing Modules\n",
    "- Editing the file\n",
    "- Concatenating strings\n",
    "- Loading the Onset Files\n",
    "- Running the Script\n",
    "\n",
    "## Notes\n",
    "- Script targets all 26 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TUTORIAL #6: BATCH SCRIPTING - AUTOMATION FRAMEWORK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def get_subject_list(dataset_path=\"ds000102\", pattern=\"sub-*\"):\n",
    "    \"\"\"Get list of subjects from dataset\"\"\"\n",
    "    import glob\n",
    "    subjects = sorted(glob.glob(f\"{dataset_path}/{pattern}\"))\n",
    "    subjects = [s.split('/')[-1] for s in subjects]\n",
    "    return subjects\n",
    "\n",
    "def load_subject_data(subject_id, run_id=1, dataset_path=\"ds000102\"):\n",
    "    \"\"\"Load behavioral and fMRI data for a subject/run\"\"\"\n",
    "    events_file = f\"{dataset_path}/{subject_id}/func/{subject_id}_task-flanker_run-{run_id}_events.tsv\"\n",
    "    bold_file = f\"{dataset_path}/{subject_id}/func/{subject_id}_task-flanker_run-{run_id}_bold.nii.gz\"\n",
    "    try:\n",
    "        events = pd.read_csv(events_file, sep=\"\\t\")\n",
    "        return {'subject': subject_id, 'run': run_id, 'events': events, 'bold_file': bold_file}\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "def calculate_behavioral_metrics(events_df):\n",
    "    \"\"\"Calculate behavioral metrics from events dataframe\"\"\"\n",
    "    metrics = {\n",
    "        'n_trials': len(events_df),\n",
    "        'accuracy': (events_df['correctness'] == 'correct').sum() / len(events_df),\n",
    "        'mean_rt': events_df['response_time'].mean(),\n",
    "        'std_rt': events_df['response_time'].std(),\n",
    "        'congruent_rt': events_df[events_df['Stimulus'] == 'congruent']['response_time'].mean(),\n",
    "        'incongruent_rt': events_df[events_df['Stimulus'] == 'incongruent']['response_time'].mean(),\n",
    "    }\n",
    "    metrics['flanker_effect'] = metrics['incongruent_rt'] - metrics['congruent_rt']\n",
    "    return metrics\n",
    "\n",
    "subject_list = get_subject_list()\n",
    "print(f\"\\nDataset contains {len(subject_list)} subjects:\")\n",
    "print(f\"  {', '.join(subject_list[:10])}{'...' if len(subject_list) > 10 else ''}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"BATCH PROCESSING SUMMARY\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "batch_results = []\n",
    "for subject_id in subject_list[:5]:\n",
    "    for run_id in [1, 2]:\n",
    "        data = load_subject_data(subject_id, run_id)\n",
    "        if data is not None:\n",
    "            metrics = calculate_behavioral_metrics(data['events'])\n",
    "            batch_results.append({\n",
    "                'Subject': subject_id,\n",
    "                'Run': run_id,\n",
    "                'N_Trials': metrics['n_trials'],\n",
    "                'Accuracy': f\"{metrics['accuracy']:.1%}\",\n",
    "                'Mean_RT': f\"{metrics['mean_rt']:.3f}s\",\n",
    "                'Flanker_Effect': f\"{metrics['flanker_effect']*1000:.0f}ms\",\n",
    "            })\n",
    "\n",
    "batch_df = pd.DataFrame(batch_results)\n",
    "print(f\"\\n{batch_df.to_string(index=False)}\")\n",
    "\n",
    "print(f\"\\n✓ Batch processing framework ready\")\n",
    "print(f\"✓ Total runs to process: {len(subject_list) * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff03d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## Batch Processing Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Batch Processing Summary: First 5 Subjects', fontsize=14, fontweight='bold')\n",
    "\n",
    "full_batch_results = []\n",
    "for subject_id in subject_list[:5]:\n",
    "    for run_id in [1, 2]:\n",
    "        data = load_subject_data(subject_id, run_id)\n",
    "        if data is not None:\n",
    "            metrics = calculate_behavioral_metrics(data['events'])\n",
    "            full_batch_results.append({\n",
    "                'Subject': subject_id,\n",
    "                'Run': run_id,\n",
    "                'Accuracy': metrics['accuracy'],\n",
    "                'Mean_RT': metrics['mean_rt'],\n",
    "                'Flanker_Effect': metrics['flanker_effect'],\n",
    "            })\n",
    "\n",
    "full_batch_df = pd.DataFrame(full_batch_results)\n",
    "\n",
    "ax = axes[0, 0]\n",
    "subjects_unique = full_batch_df['Subject'].unique()\n",
    "x_pos = np.arange(len(subjects_unique))\n",
    "for run_id in [1, 2]:\n",
    "    run_data = full_batch_df[full_batch_df['Run'] == run_id]\n",
    "    acc_values = [run_data[run_data['Subject'] == s]['Accuracy'].values[0] if len(run_data[run_data['Subject'] == s]) > 0 else 0\n",
    "                  for s in subjects_unique]\n",
    "    ax.bar(x_pos + (run_id-1)*0.4, acc_values, width=0.4, label=f'Run {run_id}', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Subject', fontweight='bold')\n",
    "ax.set_ylabel('Accuracy', fontweight='bold')\n",
    "ax.set_title('Behavioral Accuracy Across Subjects', fontweight='bold')\n",
    "ax.set_xticks(x_pos + 0.2)\n",
    "ax.set_xticklabels(subjects_unique, rotation=45)\n",
    "ax.set_ylim([0.8, 1.0])\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "for run_id in [1, 2]:\n",
    "    run_data = full_batch_df[full_batch_df['Run'] == run_id]\n",
    "    rt_values = [run_data[run_data['Subject'] == s]['Mean_RT'].values[0] if len(run_data[run_data['Subject'] == s]) > 0 else 0\n",
    "                 for s in subjects_unique]\n",
    "    ax.bar(x_pos + (run_id-1)*0.4, rt_values, width=0.4, label=f'Run {run_id}', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Subject', fontweight='bold')\n",
    "ax.set_ylabel('Mean Response Time (s)', fontweight='bold')\n",
    "ax.set_title('Mean RT Across Subjects', fontweight='bold')\n",
    "ax.set_xticks(x_pos + 0.2)\n",
    "ax.set_xticklabels(subjects_unique, rotation=45)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[1, 0]\n",
    "for run_id in [1, 2]:\n",
    "    run_data = full_batch_df[full_batch_df['Run'] == run_id]\n",
    "    flanker_values = [run_data[run_data['Subject'] == s]['Flanker_Effect'].values[0] * 1000 if len(run_data[run_data['Subject'] == s]) > 0 else 0\n",
    "                      for s in subjects_unique]\n",
    "    ax.bar(x_pos + (run_id-1)*0.4, flanker_values, width=0.4, label=f'Run {run_id}', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Subject', fontweight='bold')\n",
    "ax.set_ylabel('Flanker Effect (ms)', fontweight='bold')\n",
    "ax.set_title('Conflict Effect: Incongruent > Congruent', fontweight='bold')\n",
    "ax.set_xticks(x_pos + 0.2)\n",
    "ax.set_xticklabels(subjects_unique, rotation=45)\n",
    "ax.axhline(0, color='k', linestyle='--', alpha=0.3)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.violinplot([full_batch_df['Accuracy'].values], positions=[1], showmeans=True, showmedians=True)\n",
    "ax.violinplot([full_batch_df['Mean_RT'].values * 1000], positions=[2], showmeans=True, showmedians=True)\n",
    "ax.violinplot([full_batch_df['Flanker_Effect'].values * 1000], positions=[3], showmeans=True, showmedians=True)\n",
    "\n",
    "ax.set_xticks([1, 2, 3])\n",
    "ax.set_xticklabels(['Accuracy', 'Mean RT (ms)', 'Flanker Effect (ms)'])\n",
    "ax.set_ylabel('Value', fontweight='bold')\n",
    "ax.set_title('Behavioral Metrics Distribution', fontweight='bold')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('batch_processing_summary.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Batch Processing Visualization Complete\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
